{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: A Machine Learning Approach to SMS Spam Detection\n",
    "\n",
    "Currently, the use of cell phones has surged in the last decade, leading, among other things, to a problem regarding text messages with promotions from unscrupulous marketing agents, and with fraudulent messages that can lead us to have a bad day. To solve this problem, in this project we will focus building a m achine learning model that accurately allows us to predict and identify when a received text message is spam or not (ham), with the help of the text body of SMS, while using a [SMS Spam Collection Dataset from kaggle.com](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset) with a total of 5,169 unique and legitimate text messages downloaded fro m the Kaggle website.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Analyze the provided SMS dataset to understand the characteristics of spam and\n",
    "legitimate (ham) messages.\n",
    "* Explore the content of messages, examining factors like message length, common words,\n",
    "and phrases.\n",
    "* Develop and train a spam detection model using a machine learning algorithm.\n",
    "* Assess the performance of the model through testing and validation.\n",
    "* Implement the trained model to classify new messages and measure its accuracy in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, ' PO Box 5249',\n",
       "       ' the person is definitely special for u..... But if the person is so special',\n",
       "       ' HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE JEN XXX\\\\\"\"',\n",
       "       ' wanted to say hi. HI!!!\\\\\" Stop? Send STOP to 62468\"',\n",
       "       'this wont even start........ Datz confidence..\"', 'GN',\n",
       "       '.;-):-D\"',\n",
       "       'just been in bedbut mite go 2 thepub l8tr if uwana mt up?loads a luv Jenxxx.\\\\\"\"',\n",
       "       ' bt not his girlfrnd... G o o d n i g h t . . .@\"',\n",
       "       ' I\\'ll come up\"',\n",
       "       ' don\\'t miss ur best life for anything... Gud nyt...\"',\n",
       "       ' just as a shop has to give a guarantee on what they sell. B. G.\"',\n",
       "       ' But at d end my love compromised me for everything:-(\\\\\".. Gud mornin:-)\"',\n",
       "       ' the toughest is acting Happy with all unspoken pain inside..\\\\\"\"',\n",
       "       ' smoke hella weed\\\\\"\"', '\\\\\" not \\\\\"what i need to do.\\\\\"\"',\n",
       "       'JUST GOT PAYED2DAY & I HAVBEEN GIVEN Aå£50 PAY RISE 4MY WORK & HAVEBEEN MADE PRESCHOOLCO-ORDINATOR 2I AM FEELINGOOD LUV\\\\\"\"',\n",
       "       ' justthought iåÕd sayhey! how u doin?nearly the endof me wk offdam nevamind!We will have 2Hook up sn if uwant m8? loveJen x.\\\\\"\"',\n",
       "       'JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIGNORE MYCALLS',\n",
       "       'u hav2hear it!c u sn xxxx\\\\\"\"', \" I don't mind\",\n",
       "       ' Dont Come Near My Body..!! Bcoz My Hands May Not Come 2 Wipe Ur Tears Off That Time..!Gud ni8\"',\n",
       "       \"Well there's still a bit left if you guys want to tonight\",\n",
       "       ' but dont try to prove\\\\\" ..... Gud mrng...\"',\n",
       "       ' SHE SHUDVETOLD U. DID URGRAN KNOW?NEWAY',\n",
       "       ' but watever u shared should be true\\\\\"....\"',\n",
       "       ' like you are the KING\\\\\"...! OR \\\\\"Walk like you Dont care',\n",
       "       ' HAD A COOL NYTHO', ' PO Box 1146 MK45 2WT (2/3)\"',\n",
       "       ' \\\\\"It is d wonderful fruit that a tree gives when it is being hurt by a stone.. Good night......\"',\n",
       "       ' we made you hold all the weed\\\\\"\"',\n",
       "       ' but dont try to prove it..\\\\\" .Gud noon....\"',\n",
       "       ' its a miracle to Love a person who can\\'t Love anyone except U...\\\\\" Gud nyt...\"',\n",
       "       ' Gud night....\"',\n",
       "       ' that\\'s the tiny street where the parking lot is\"',\n",
       "       'PROBPOP IN & CU SATTHEN HUNNY 4BREKKIE! LOVE JEN XXX. PSXTRA LRG PORTIONS 4 ME PLEASE \\\\\"\"',\n",
       "       ' hopeSo hunny. i amnow feelin ill & ithink i may have tonsolitusaswell! damn iam layin in bedreal bored. lotsof luv me xxxx\\\\\"\"',\n",
       "       ' GOD said',\n",
       "       ' always give response 2 who cares 4 U\\\\\"... Gud night..swt dreams..take care\"',\n",
       "       ' HOPE UR OK... WILL GIVE U A BUZ WEDLUNCH. GO OUTSOMEWHERE 4 ADRINK IN TOWN..CUD GO 2WATERSHD 4 A BIT? PPL FROMWRK WILL BTHERE. LOVE PETEXXX.\\\\\"\"',\n",
       "       ' b\\'coz nobody will fight for u. Only u &amp; u have to fight for ur self &amp; win the battle. -VIVEKANAND- G 9t.. SD..\"',\n",
       "       'DEVIOUSBITCH.ANYWAY',\n",
       "       ' ENJOYIN INDIANS AT THE MO..yeP. SaLL gOoD HehE ;> hows bout u shexy? Pete Xx\\\\\"\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary columns\n",
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='v1', data=df, orient='v')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of ham and spam messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point crazy Available only in ...\n",
       "1   ham                            Ok lar Joking wif u oni\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham        U dun say so early hor U c already then say\n",
       "4   ham  Nah I dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['v2'] = df['v2'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length\n",
       "0   ham  Go until jurong point crazy Available only in ...     102\n",
       "1   ham                            Ok lar Joking wif u oni      23\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149\n",
       "3   ham        U dun say so early hor U c already then say      43\n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column to represent the length of the text\n",
    "df['length'] = df['v2'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20\n",
       "1   ham                            Ok lar Joking wif u oni      23      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28\n",
       "3   ham        U dun say so early hor U c already then say      43     11\n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column with the number of words\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df['words'] = df['v2'].apply(count_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columm class for the target variable\n",
    "\n",
    "df['Class'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources (do this only once)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text_nltk(text):\n",
    "  # Lowercase the text\n",
    "  text = text.lower()\n",
    "  # Tokenize using NLTK word_tokenize\n",
    "  tokens = word_tokenize(text)\n",
    "  return tokens\n",
    "\n",
    "df['tokens_nltk'] = df['v2'].apply(tokenize_text_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  \n",
       "0      0  [go, until, jurong, point, crazy, available, o...  \n",
       "1      0                     [ok, lar, joking, wif, u, oni]  \n",
       "2      1  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3      0  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4      0  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  \n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1      0                     [ok, lar, joking, wif, u, oni]  \n",
       "2      1  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4      0  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK resources (do this only once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in stop_words]\n",
    "\n",
    "df['tokens_nltk'] = df['tokens_nltk'].apply(remove_stopwords)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "      <th>words_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  words_nltk  \n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...          16  \n",
       "1      0                     [ok, lar, joking, wif, u, oni]           6  \n",
       "2      1  [free, entry, 2, wkly, comp, win, fa, cup, fin...          23  \n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]           9  \n",
       "4      0  [nah, dont, think, goes, usf, lives, around, t...           8  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column with the number of words for nltk tokens\n",
    "\n",
    "def count_words_nltk(tokens):\n",
    "    return len(tokens)\n",
    "\n",
    "df['words_nltk'] = df['tokens_nltk'].apply(count_words_nltk)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming/Lemmatization: Stemming reduces words to their base form (e.g., \"running\" becomes \"run\"). Lemmatization goes a step further, considering the part of speech (e.g., \"better\" becomes \"good\"). Choose the approach that aligns with your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "      <th>words_nltk</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>16</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>6</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>23</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>9</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>8</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  words_nltk  \\\n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...          16   \n",
       "1      0                     [ok, lar, joking, wif, u, oni]           6   \n",
       "2      1  [free, entry, 2, wkly, comp, win, fa, cup, fin...          23   \n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]           9   \n",
       "4      0  [nah, dont, think, goes, usf, lives, around, t...           8   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming/Lemmatization: using NLTK\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources (do this only once)\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = PorterStemmer() # or LancasterStemmer\n",
    "lemmatizer = WordNetLemmatizer() # or SnowballStemmer\n",
    "\n",
    "def stem_text(tokens):\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "df['stemmed'] = df['tokens_nltk'].apply(stem_text)\n",
    "df['lemmatized'] = df['tokens_nltk'].apply(lemmatize_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams: Creating sequences of n words. Bigrams (2 words) and trigrams (3 words). N-grams can capture word relationships that single words might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "      <th>words_nltk</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>16</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[(go, jurong), (jurong, point), (point, crazy)...</td>\n",
       "      <td>[(go, jurong, point), (jurong, point, crazy), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>6</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[(ok, lar), (lar, joking), (joking, wif), (wif...</td>\n",
       "      <td>[(ok, lar, joking), (lar, joking, wif), (jokin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>23</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[(free, entry), (entry, 2), (2, wkly), (wkly, ...</td>\n",
       "      <td>[(free, entry, 2), (entry, 2, wkly), (2, wkly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>9</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[(u, dun), (dun, say), (say, early), (early, h...</td>\n",
       "      <td>[(u, dun, say), (dun, say, early), (say, early...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>8</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "      <td>[(nah, dont), (dont, think), (think, go), (go,...</td>\n",
       "      <td>[(nah, dont, think), (dont, think, go), (think...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  words_nltk  \\\n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...          16   \n",
       "1      0                     [ok, lar, joking, wif, u, oni]           6   \n",
       "2      1  [free, entry, 2, wkly, comp, win, fa, cup, fin...          23   \n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]           9   \n",
       "4      0  [nah, dont, think, goes, usf, lives, around, t...           8   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, go, usf, life, around, though]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(go, jurong), (jurong, point), (point, crazy)...   \n",
       "1  [(ok, lar), (lar, joking), (joking, wif), (wif...   \n",
       "2  [(free, entry), (entry, 2), (2, wkly), (wkly, ...   \n",
       "3  [(u, dun), (dun, say), (say, early), (early, h...   \n",
       "4  [(nah, dont), (dont, think), (think, go), (go,...   \n",
       "\n",
       "                                            trigrams  \n",
       "0  [(go, jurong, point), (jurong, point, crazy), ...  \n",
       "1  [(ok, lar, joking), (lar, joking, wif), (jokin...  \n",
       "2  [(free, entry, 2), (entry, 2, wkly), (2, wkly,...  \n",
       "3  [(u, dun, say), (dun, say, early), (say, early...  \n",
       "4  [(nah, dont, think), (dont, think, go), (think...  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-grams\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def extract_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "df['bigrams'] = df['lemmatized'].apply(lambda x: extract_ngrams(x, 2))\n",
    "df['trigrams'] = df['lemmatized'].apply(lambda x: extract_ngrams(x, 3))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens_nltk</th>\n",
       "      <th>words_nltk</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>16</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[(go, jurong), (jurong, point), (point, crazy)...</td>\n",
       "      <td>[(go, jurong, point), (jurong, point, crazy), ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>6</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[(ok, lar), (lar, joking), (joking, wif), (wif...</td>\n",
       "      <td>[(ok, lar, joking), (lar, joking, wif), (jokin...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>23</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[(free, entry), (entry, 2), (2, wkly), (wkly, ...</td>\n",
       "      <td>[(free, entry, 2), (entry, 2, wkly), (2, wkly,...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>9</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[(u, dun), (dun, say), (say, early), (early, h...</td>\n",
       "      <td>[(u, dun, say), (dun, say, early), (say, early...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>8</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "      <td>[(nah, dont), (dont, think), (think, go), (go,...</td>\n",
       "      <td>[(nah, dont, think), (dont, think, go), (think...</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  length  words  \\\n",
       "0   ham  Go until jurong point crazy Available only in ...     102     20   \n",
       "1   ham                            Ok lar Joking wif u oni      23      6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     149     28   \n",
       "3   ham        U dun say so early hor U c already then say      43     11   \n",
       "4   ham  Nah I dont think he goes to usf he lives aroun...      59     13   \n",
       "\n",
       "   Class                                        tokens_nltk  words_nltk  \\\n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...          16   \n",
       "1      0                     [ok, lar, joking, wif, u, oni]           6   \n",
       "2      1  [free, entry, 2, wkly, comp, win, fa, cup, fin...          23   \n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]           9   \n",
       "4      0  [nah, dont, think, goes, usf, lives, around, t...           8   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, go, usf, life, around, though]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(go, jurong), (jurong, point), (point, crazy)...   \n",
       "1  [(ok, lar), (lar, joking), (joking, wif), (wif...   \n",
       "2  [(free, entry), (entry, 2), (2, wkly), (wkly, ...   \n",
       "3  [(u, dun), (dun, say), (say, early), (early, h...   \n",
       "4  [(nah, dont), (dont, think), (think, go), (go,...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(go, jurong, point), (jurong, point, crazy), ...   \n",
       "1  [(ok, lar, joking), (lar, joking, wif), (jokin...   \n",
       "2  [(free, entry, 2), (entry, 2, wkly), (2, wkly,...   \n",
       "3  [(u, dun, say), (dun, say, early), (say, early...   \n",
       "4  [(nah, dont, think), (dont, think, go), (think...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4           nah dont think go usf life around though  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert lemmatized tokens back to text\n",
    "\n",
    "def tokens_to_text(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['lemmatized_text'] = df['lemmatized'].apply(tokens_to_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 8841)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag-of-Words (BoW)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer\n",
    "vectorizer.fit(df['lemmatized_text'])\n",
    "\n",
    "# Transform the text to a bag-of-words vector\n",
    "X = vectorizer.transform(df['lemmatized_text'])\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix\n",
    "X = X.toarray()\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089my</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>0207</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>...</th>\n",
       "      <th>ìï</th>\n",
       "      <th>ìïll</th>\n",
       "      <th>ûthanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   008704050406  0089my  0121  01223585236  01223585334  0125698789  02  \\\n",
       "0             0       0     0            0            0           0   0   \n",
       "1             0       0     0            0            0           0   0   \n",
       "2             0       0     0            0            0           0   0   \n",
       "3             0       0     0            0            0           0   0   \n",
       "4             0       0     0            0            0           0   0   \n",
       "\n",
       "   020603  0207  02070836089  ...  ìï  ìïll  ûthanks  ûªm  ûªt  ûªve  ûï  \\\n",
       "0       0     0            0  ...   0     0        0    0    0     0   0   \n",
       "1       0     0            0  ...   0     0        0    0    0     0   0   \n",
       "2       0     0            0  ...   0     0        0    0    0     0   0   \n",
       "3       0     0            0  ...   0     0        0    0    0     0   0   \n",
       "4       0     0            0  ...   0     0        0    0    0     0   0   \n",
       "\n",
       "   ûïharry  ûò  ûówell  \n",
       "0        0   0       0  \n",
       "1        0   0       0  \n",
       "2        0   0       0  \n",
       "3        0   0       0  \n",
       "4        0   0       0  \n",
       "\n",
       "[5 rows x 8841 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(X, columns=vectorizer.get_feature_names_out())\n",
    "x.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
